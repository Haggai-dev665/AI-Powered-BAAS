{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model Training - Text Classification\n",
    "\n",
    "This notebook demonstrates training custom AI models for the AI-Powered BaaS platform.\n",
    "We'll create a text classification model for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch transformers scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Load and prepare training data for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data - in production, you'd load from your database\n",
    "sample_data = [\n",
    "    {\"text\": \"I love this product! It's amazing.\", \"label\": 1},\n",
    "    {\"text\": \"This is terrible, I hate it.\", \"label\": 0},\n",
    "    {\"text\": \"Pretty good overall, would recommend.\", \"label\": 1},\n",
    "    {\"text\": \"Not worth the money, disappointing.\", \"label\": 0},\n",
    "    {\"text\": \"Excellent quality and great service!\", \"label\": 1},\n",
    "    {\"text\": \"Worst experience ever, avoid at all costs.\", \"label\": 0},\n",
    "    {\"text\": \"Satisfied with the purchase, good value.\", \"label\": 1},\n",
    "    {\"text\": \"Poor quality, broke within a week.\", \"label\": 0},\n",
    "    {\"text\": \"Outstanding product, exceeded expectations!\", \"label\": 1},\n",
    "    {\"text\": \"Complete waste of time and money.\", \"label\": 0}\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(sample_data)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Label distribution:\\n{df['label'].value_counts()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Setup\n",
    "\n",
    "Initialize the pre-trained model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 2\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Number of parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "# Prepare datasets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create dataset class\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    ")\n",
    "\n",
    "# Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions)\n",
    "    }\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Training configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "training_start = datetime.now()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "training_end = datetime.now()\n",
    "training_duration = training_end - training_start\n",
    "print(f\"Training completed in: {training_duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        confidence = torch.max(predictions).item()\n",
    "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        \n",
    "    return {\n",
    "        'sentiment': 'positive' if predicted_class == 1 else 'negative',\n",
    "        'confidence': confidence,\n",
    "        'raw_predictions': predictions.numpy()[0]\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_texts = [\n",
    "    \"This is absolutely fantastic!\",\n",
    "    \"I'm really disappointed with this.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"Best purchase I've ever made!\",\n",
    "    \"Completely useless product.\"\n",
    "]\n",
    "\n",
    "print(\"Test Predictions:\")\n",
    "for text in test_texts:\n",
    "    result = predict_sentiment(text)\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.3f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Export and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_save_path = \"./custom_sentiment_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# Create model metadata\n",
    "model_metadata = {\n",
    "    \"model_name\": \"custom-sentiment-classifier\",\n",
    "    \"base_model\": MODEL_NAME,\n",
    "    \"task\": \"text-classification\",\n",
    "    \"labels\": [\"negative\", \"positive\"],\n",
    "    \"training_date\": datetime.now().isoformat(),\n",
    "    \"training_duration\": str(training_duration),\n",
    "    \"eval_accuracy\": eval_results[\"eval_accuracy\"],\n",
    "    \"model_size\": f\"{model.num_parameters():,} parameters\",\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"training_samples\": len(train_dataset),\n",
    "    \"validation_samples\": len(val_dataset)\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "with open(f\"{model_save_path}/model_metadata.json\", \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(\"Model Metadata:\")\n",
    "print(json.dumps(model_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Integration with AI-Powered BaaS\n",
    "\n",
    "Code to integrate the trained model with the BaaS platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example integration code for the AI service\n",
    "integration_code = '''\n",
    "# Add this to your AI service (ai-services/main.py)\n",
    "\n",
    "class CustomSentimentModel:\n",
    "    def __init__(self, model_path=\"./custom_sentiment_model\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, text: str) -> dict:\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoding)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            confidence = torch.max(predictions).item()\n",
    "            predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        \n",
    "        return {\n",
    "            \"sentiment\": \"positive\" if predicted_class == 1 else \"negative\",\n",
    "            \"confidence\": confidence,\n",
    "            \"scores\": {\n",
    "                \"negative\": predictions[0][0].item(),\n",
    "                \"positive\": predictions[0][1].item()\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Initialize the custom model\n",
    "custom_sentiment_model = CustomSentimentModel()\n",
    "\n",
    "# Add endpoint\n",
    "@app.post(\"/ai/custom/sentiment\")\n",
    "async def custom_sentiment_analysis(request: SentimentAnalysisRequest):\n",
    "    start_time = datetime.utcnow()\n",
    "    \n",
    "    try:\n",
    "        result = custom_sentiment_model.predict(request.text)\n",
    "        processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        return AIResponse(\n",
    "            success=True,\n",
    "            data=result,\n",
    "            timestamp=datetime.utcnow(),\n",
    "            model_used=\"custom-sentiment-classifier\",\n",
    "            processing_time_ms=processing_time\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return AIResponse(\n",
    "            success=False,\n",
    "            error=str(e),\n",
    "            timestamp=datetime.utcnow(),\n",
    "            model_used=\"custom-sentiment-classifier\",\n",
    "            processing_time_ms=(datetime.utcnow() - start_time).total_seconds() * 1000\n",
    "        )\n",
    "'''\n",
    "\n",
    "print(\"Integration code:\")\n",
    "print(integration_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Monitoring\n",
    "\n",
    "Set up monitoring for the deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monitoring dashboard\n",
    "monitoring_code = '''\n",
    "# Model performance monitoring\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class ModelMonitor:\n",
    "    def __init__(self):\n",
    "        self.prediction_count = 0\n",
    "        self.total_processing_time = 0\n",
    "        self.confidence_scores = []\n",
    "        self.sentiment_distribution = defaultdict(int)\n",
    "        \n",
    "    def log_prediction(self, result: dict, processing_time: float):\n",
    "        self.prediction_count += 1\n",
    "        self.total_processing_time += processing_time\n",
    "        self.confidence_scores.append(result[\"confidence\"])\n",
    "        self.sentiment_distribution[result[\"sentiment\"]] += 1\n",
    "    \n",
    "    def get_stats(self):\n",
    "        if self.prediction_count == 0:\n",
    "            return {\"error\": \"No predictions logged yet\"}\n",
    "            \n",
    "        return {\n",
    "            \"total_predictions\": self.prediction_count,\n",
    "            \"avg_processing_time_ms\": self.total_processing_time / self.prediction_count,\n",
    "            \"avg_confidence\": sum(self.confidence_scores) / len(self.confidence_scores),\n",
    "            \"sentiment_distribution\": dict(self.sentiment_distribution)\n",
    "        }\n",
    "\n",
    "model_monitor = ModelMonitor()\n",
    "'''\n",
    "\n",
    "print(\"Model monitoring setup:\")\n",
    "print(monitoring_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Preparation**: Loading and preprocessing training data\n",
    "2. **Model Setup**: Initializing a pre-trained transformer model\n",
    "3. **Training**: Fine-tuning the model on custom data\n",
    "4. **Evaluation**: Testing model performance\n",
    "5. **Export**: Saving the model for deployment\n",
    "6. **Integration**: Code for integrating with the AI-Powered BaaS platform\n",
    "7. **Monitoring**: Setting up performance monitoring\n",
    "\n",
    "The trained model can now be deployed as part of the AI-Powered BaaS platform, providing custom sentiment analysis capabilities alongside the Gemini API integration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}